{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from natasha import NamesExtractor\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from natasha.markup import show_markup_notebook as show_markup\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = '..\\\\02. Data creation\\\\df.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой поступок вы назвали бы самым трусливым?</td>\n",
       "      <td>С понятием трусости у меня идет прямая ассоциа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Почему общество часто не ценит великих людей?</td>\n",
       "      <td>В истории нашей страны существует немало лично...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие цели важно ставить на жизненном пути?</td>\n",
       "      <td>Как бы это банально не звучало, но мы живем дл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Что значит быть отзывчивым?</td>\n",
       "      <td>Отзывчивость – это емкое понятие, вмещающее в ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Всегда ли хороша верность?</td>\n",
       "      <td>Верность, доверие, любовь, уважение, поддержка...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           topic  \\\n",
       "0  Какой поступок вы назвали бы самым трусливым?   \n",
       "1  Почему общество часто не ценит великих людей?   \n",
       "2    Какие цели важно ставить на жизненном пути?   \n",
       "3                    Что значит быть отзывчивым?   \n",
       "4                     Всегда ли хороша верность?   \n",
       "\n",
       "                                                text  \n",
       "0  С понятием трусости у меня идет прямая ассоциа...  \n",
       "1  В истории нашей страны существует немало лично...  \n",
       "2  Как бы это банально не звучало, но мы живем дл...  \n",
       "3  Отзывчивость – это емкое понятие, вмещающее в ...  \n",
       "4  Верность, доверие, любовь, уважение, поддержка...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stopwords_ru = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ru/master/stopwords-ru.txt\"\n",
    "\n",
    "\n",
    "def get_text(url, encoding='utf-8', to_lower=True):\n",
    "    url = str(url)\n",
    "    if url.startswith('http'):\n",
    "        r = requests.get(url)\n",
    "        if not r.ok:\n",
    "            r.raise_for_status()\n",
    "        return r.text.lower() if to_lower else r.text\n",
    "    elif os.path.exists(url):\n",
    "        with open(url, encoding=encoding) as f:\n",
    "            return f.read().lower() if to_lower else f.read()\n",
    "    else:\n",
    "        raise Exception('parameter [url] can be either URL or a filename')\n",
    "\n",
    "\n",
    "def normalize_tokens(tokens):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    return [morph.parse(tok)[0].normal_form for tok in tokens]\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens, stopwords=None, min_length=4):\n",
    "    if not stopwords:\n",
    "        return tokens\n",
    "    stopwords = set(stopwords)\n",
    "    tokens = [tok\n",
    "              for tok in tokens\n",
    "              if tok not in stopwords and len(tok) >= min_length]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tokenize_n_lemmatize(\n",
    "    text, stopwords=None, normalize=True, \n",
    "    regexp=r'(?u)\\b\\w{3,}\\b'):\n",
    "    words = [w for sent in sent_tokenize(text)\n",
    "             for w in regexp_tokenize(sent, regexp)]\n",
    "    if normalize:\n",
    "        words = normalize_tokens(words)\n",
    "    if stopwords:\n",
    "        words = remove_stopwords(words, stopwords)\n",
    "    return words\n",
    "\n",
    "stopwords_ru = get_text(url_stopwords_ru).splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df(df):\n",
    "    nrows = len(df)\n",
    "    #text_parsed_list = []\n",
    "    topic_parsed_list = []\n",
    "    for row in range(0, nrows):\n",
    "        #text = df.loc[row]['text']\n",
    "        topic = df.loc[row]['topic']\n",
    "        #text = text.replace('\\n', ' ')\n",
    "        #text_parsed_list.append(' '.join(tokenize_n_lemmatize(text)))\n",
    "        topic_parsed_list.append(' '.join(tokenize_n_lemmatize(topic)))\n",
    "    #df['text_parsed'] = text_parsed_list\n",
    "    df['topic_parsed'] = topic_parsed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой поступок вы назвали бы самым трусливым?</td>\n",
       "      <td>С понятием трусости у меня идет прямая ассоциа...</td>\n",
       "      <td>какой поступок назвать самый трусливый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Почему общество часто не ценит великих людей?</td>\n",
       "      <td>В истории нашей страны существует немало лично...</td>\n",
       "      <td>почему общество часто ценить великое человек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие цели важно ставить на жизненном пути?</td>\n",
       "      <td>Как бы это банально не звучало, но мы живем дл...</td>\n",
       "      <td>какой цель важный ставить жизненный путь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Что значит быть отзывчивым?</td>\n",
       "      <td>Отзывчивость – это емкое понятие, вмещающее в ...</td>\n",
       "      <td>что значит быть отзывчивый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Всегда ли хороша верность?</td>\n",
       "      <td>Верность, доверие, любовь, уважение, поддержка...</td>\n",
       "      <td>всегда хороший верность</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           topic  \\\n",
       "0  Какой поступок вы назвали бы самым трусливым?   \n",
       "1  Почему общество часто не ценит великих людей?   \n",
       "2    Какие цели важно ставить на жизненном пути?   \n",
       "3                    Что значит быть отзывчивым?   \n",
       "4                     Всегда ли хороша верность?   \n",
       "\n",
       "                                                text  \\\n",
       "0  С понятием трусости у меня идет прямая ассоциа...   \n",
       "1  В истории нашей страны существует немало лично...   \n",
       "2  Как бы это банально не звучало, но мы живем дл...   \n",
       "3  Отзывчивость – это емкое понятие, вмещающее в ...   \n",
       "4  Верность, доверие, любовь, уважение, поддержка...   \n",
       "\n",
       "                                   topic_parsed  \n",
       "0        какой поступок назвать самый трусливый  \n",
       "1  почему общество часто ценить великое человек  \n",
       "2      какой цель важный ставить жизненный путь  \n",
       "3                    что значит быть отзывчивый  \n",
       "4                       всегда хороший верность  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим Bag of Words для именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчет схожести строк по коэффициенту Жаккара\n",
    "def dist_jaccard(str1, str2):\n",
    "    a = len(str1)\n",
    "    b = len(str2)\n",
    "    c = 0\n",
    "    while str1 != '':\n",
    "        s = str1[0]\n",
    "        r = re.compile(s)\n",
    "        c += min(len(r.findall(str1)), len(r.findall(str2)))\n",
    "        str1 = r.sub('', str1)\n",
    "        str2 = r.sub('', str2)\n",
    "    return c / (a + b - c)\n",
    "\n",
    "# Функция создания массива, который выделяет похожие строки в группы \n",
    "def make_groups(names):\n",
    "    n = len(names)\n",
    "    groups = np.array([-1] * n)\n",
    "    gr = 1\n",
    "    for i in range(n):\n",
    "        j = i + 1\n",
    "        while j != n:\n",
    "            if dist_jaccard(names[i], names[j]) >= 0.6:\n",
    "                if groups[i] == -1 and groups[j] == -1:\n",
    "                    groups[i] = gr\n",
    "                    groups[j] = gr\n",
    "                    gr += 1\n",
    "                elif groups[i] == -1:\n",
    "                    groups[i] = groups[j]\n",
    "                elif groups[j] == -1:\n",
    "                    groups[j] = groups[i]\n",
    "                elif groups[i] != groups[j]:\n",
    "                    groups[np.where(groups == groups[j])] = groups[i]\n",
    "            j += 1\n",
    "    for i in range(n):\n",
    "        if groups[i] == -1:\n",
    "            groups[i] = gr\n",
    "            gr += 1\n",
    "    return groups\n",
    "\n",
    "# Функция выделения именованных сущностей из текста и распределения их по группам\n",
    "def extract_names(text):\n",
    "    extractor = NamesExtractor()\n",
    "    matches = extractor(text)\n",
    "    result = np.array([])\n",
    "    for match in matches:\n",
    "        name = ''\n",
    "        if match.fact.first != None:\n",
    "                name += match.fact.first\n",
    "        if match.fact.middle != None:\n",
    "                name += ' ' + match.fact.middle\n",
    "        if match.fact.last != None:\n",
    "                name += ' ' + match.fact.last\n",
    "        name = name.lower()\n",
    "        result= np.append(result, name)\n",
    "    return result, make_groups(result)\n",
    "\n",
    "# Функция сравнения двух групп именовааных сущностей\n",
    "def compare_groups(group1, group2):\n",
    "    n = 0\n",
    "    agg_dj = 0\n",
    "    for el1 in group1:\n",
    "        for el2 in group2:\n",
    "            agg_dj += dist_jaccard(el1, el2)\n",
    "            n += 1\n",
    "\n",
    "    agg_dj /= n\n",
    "    if agg_dj >=0.6:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def normalize_matrix_by_column(matrix):\n",
    "    n = matrix.shape[0]\n",
    "    m = matrix.shape[1]\n",
    "    norm_matrix = np.zeros((n, m))\n",
    "    for j in range(m):\n",
    "        nu = np.mean(matrix[:,j])\n",
    "        std = np.std(matrix[:,j])\n",
    "        for i in range(n):\n",
    "            if std != 0:\n",
    "                norm_matrix[i,j] = float((matrix[i,j]-nu)/std) \n",
    "            else:\n",
    "                norm_matrix[i,j] = 0.\n",
    "    return norm_matrix\n",
    "\n",
    "# Функция создания матрицы: строки - тексты, столбцы - именованные сущности (а точнее группы)\n",
    "def make_named_enteties_matrix(df):\n",
    "    groups_in_matrix = np.array([])\n",
    "    text_group_pairs = []\n",
    "    n = len(df)\n",
    "    \n",
    "    for i in range(n):\n",
    "        names, groups = extract_names(df.loc[i]['text'])\n",
    "        set_of_groups = set(groups)\n",
    "        \n",
    "        for group in set_of_groups:\n",
    "            group_in_text = names[np.where(groups == group)]\n",
    "            is_group_found = False\n",
    "            m = len(groups_in_matrix)\n",
    "            \n",
    "            for j in range(m):\n",
    "                if compare_groups(group_in_text, groups_in_matrix[j]):\n",
    "                    groups_in_matrix[j] = groups_in_matrix[j].union(set(group_in_text))\n",
    "                    text_group_pairs.append((i,j))\n",
    "                    is_group_found = True\n",
    "                    break\n",
    "                    \n",
    "            if not is_group_found:\n",
    "                groups_in_matrix = np.append(groups_in_matrix, set(group_in_text))\n",
    "                text_group_pairs.append((i,m))\n",
    "                \n",
    "    m = len(groups_in_matrix)\n",
    "    matrix = np.zeros((n,m))\n",
    "    for el in text_group_pairs:\n",
    "        matrix[el] += 1\n",
    "    return matrix, groups_in_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'швабрин', ' швабрин'} {'пётр гринев', ' гринев'} {'евгений онегин'}\n",
      " {' онегин'} {'евгений'}\n",
      " {'иван николаевич понырёв', 'алексей иванович швабрин', 'николай иванович'}\n",
      " {'пётр'} {' пугачев'} {'владимир ленский'} {'данко'}]\n"
     ]
    }
   ],
   "source": [
    "named_entity_matrix, groups_in_matrix = make_named_enteties_matrix(df)\n",
    "print(groups_in_matrix[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составим матрицу Bag of Words для тем сочинений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 118)\n"
     ]
    }
   ],
   "source": [
    "topic_matrix =  vectorizer.fit_transform(df['topic_parsed']).toarray()\n",
    "print(topic_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_topics = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составим корреляционную матрицу между *topic_matrix* и *named_entity_matrix* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix_norm = normalize_matrix_by_column(topic_matrix)\n",
    "named_entity_matrix_norm = normalize_matrix_by_column(named_entity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 118)\n"
     ]
    }
   ],
   "source": [
    "m = named_entity_matrix_norm.shape[1]\n",
    "k = topic_matrix_norm.shape[1]\n",
    "corr_matrix = np.zeros((m,k))\n",
    "print(corr_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    for j in range(k):\n",
    "        corr_matrix[i,j] = pearsonr(named_entity_matrix_norm[:,i], topic_matrix_norm[:,j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04941662 -0.04941662 -0.07073279 ... -0.1025641  -0.04941662\n",
      "  -0.04941662]\n",
      " [-0.03407991 -0.03407991 -0.04878049 ... -0.07073279 -0.03407991\n",
      "  -0.03407991]\n",
      " [-0.06213698 -0.06213698 -0.08894014 ...  0.10209743 -0.06213698\n",
      "  -0.06213698]\n",
      " ...\n",
      " [-0.02380952 -0.02380952 -0.03407991 ... -0.04941662 -0.02380952\n",
      "  -0.02380952]\n",
      " [-0.02380952 -0.02380952 -0.03407991 ... -0.04941662 -0.02380952\n",
      "  -0.02380952]\n",
      " [-0.02380952 -0.02380952 -0.03407991 ... -0.04941662 -0.02380952\n",
      "  -0.02380952]]\n"
     ]
    }
   ],
   "source": [
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' пугачев'} назвать\n",
      "{' чичиков'} цель\n",
      "{'а и солженицын'} значит\n",
      "{' желтковая'} верность\n",
      "{' свидригайлов'} оправдывать\n",
      "{' старцев'} опасный\n",
      "{'вернер'} друг\n",
      "{' ленский'} враг\n",
      "{'и а бунин'} история\n",
      "{'руфь'} жить\n"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "for i in range(m):\n",
    "    for j in range(k):\n",
    "        if corr_matrix[i,j] > 0.95:\n",
    "            print(groups_in_matrix[i], words_in_topics[j])\n",
    "            z += 1\n",
    "            break\n",
    "    if z == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('named_entity_matrix.pickle', 'wb') as output:\n",
    "    pickle.dump(named_entity_matrix, output)\n",
    "    \n",
    "with open('groups_in_matrix.pickle', 'wb') as output:\n",
    "    pickle.dump(groups_in_matrix, output)\n",
    "\n",
    "with open('vectorizer.pickle', 'wb') as output:\n",
    "    pickle.dump(vectorizer, output)\n",
    "\n",
    "with open('df_parsed.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
